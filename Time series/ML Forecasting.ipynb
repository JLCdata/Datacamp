{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f7bf52d",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64bb354",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(15, 7), sharex=True, sharey=True)\n",
    "\n",
    "# Calculate the time array\n",
    "time = np.arange(normal.shape[0]) / sfreq\n",
    "\n",
    "# Stack the normal/abnormal audio so you can loop and plot\n",
    "stacked_audio = np.hstack([normal, abnormal]).T\n",
    "\n",
    "# Loop through each audio file / ax object and plot\n",
    "# .T.ravel() transposes the array, then unravels it into a 1-D vector for looping\n",
    "for iaudio, ax in zip(stacked_audio, axs.T.ravel()):\n",
    "    ax.plot(time, iaudio)\n",
    "show_plot_and_make_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293bb3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average across the audio files of each DataFrame\n",
    "mean_normal = np.mean(normal, axis=1)\n",
    "mean_abnormal = np.mean(abnormal, axis=1)\n",
    "\n",
    "# Plot each average over time\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3), sharey=True)\n",
    "ax1.plot(time, mean_normal)\n",
    "ax1.set(title=\"Normal Data\")\n",
    "ax2.plot(time, mean_abnormal)\n",
    "ax2.set(title=\"Abnormal Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5069a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions and score them manually\n",
    "predictions = model.predict(X_test)\n",
    "print(sum(predictions == y_test.squeeze()) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f1685",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfc0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a rolling window with Pandas, excluding the right-most datapoint of the window\n",
    "prices_perc_rolling = prices_perc.rolling(20, min_periods=5, closed='right')\n",
    "\n",
    "# Define the features you'll calculate for each window\n",
    "features_to_calculate = [np.min, np.max, np.mean, np.std]\n",
    "\n",
    "# Calculate these features for your rolling window object\n",
    "features = prices_perc_rolling.aggregate(features_to_calculate)\n",
    "\n",
    "# Plot the results\n",
    "ax = features.loc[:\"2011-01\"].plot()\n",
    "prices_perc.loc[:\"2011-01\"].plot(ax=ax, color='k', alpha=.2, lw=3)\n",
    "ax.legend(loc=(1.01, .6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d6ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import partial from functools\n",
    "from functools import partial\n",
    "percentiles = [1, 10, 25, 50, 75, 90, 99]\n",
    "\n",
    "# Use a list comprehension to create a partial function for each quantile\n",
    "percentile_functions = [partial(np.percentile, q=percentile) for percentile in percentiles]\n",
    "\n",
    "# Calculate each of these quantiles on the data using a rolling window\n",
    "prices_perc_rolling = prices_perc.rolling(20, min_periods=5, closed='right')\n",
    "features_percentiles = prices_perc_rolling.aggregate(percentile_functions)\n",
    "\n",
    "# Plot a subset of the result\n",
    "ax = features_percentiles.loc[:\"2011-01\"].plot(cmap=plt.cm.viridis)\n",
    "ax.legend(percentiles, loc=(1.01, .5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19a008",
   "metadata": {},
   "source": [
    "# Lags como features en modelos ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439040c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the \"time lags\"\n",
    "shifts = np.arange(1, 11).astype(int)\n",
    "\n",
    "# Use a dictionary comprehension to create name: value pairs, one pair per shift\n",
    "shifted_data = {\"lag_{}_day\".format(day_shift): prices_perc.shift(day_shift) for day_shift in shifts}\n",
    "\n",
    "# Convert into a DataFrame for subsequent use\n",
    "prices_perc_shifted = pd.DataFrame(shifted_data)\n",
    "\n",
    "# Plot the first 100 samples of each\n",
    "ax = prices_perc_shifted.iloc[:100].plot(cmap=plt.cm.viridis)\n",
    "prices_perc.iloc[:100].plot(color='r', lw=2)\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with the median for each column\n",
    "X = prices_perc_shifted.fillna(np.nanmedian(prices_perc_shifted))\n",
    "y = prices_perc.fillna(np.nanmedian(prices_perc))\n",
    "\n",
    "# Fit the model\n",
    "model = Ridge()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_coefficients(coefs, names, ax):\n",
    "    # Make a bar plot for the coefficients, including their names on the x-axis\n",
    "    ax.bar(names, coefs)\n",
    "    ax.set(xlabel='Coefficient name', ylabel='Coefficient value')\n",
    "    \n",
    "    # Set formatting so it looks nice\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c492849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the output data up to \"2011-01\"\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "y.loc[:'2011-01'].plot(ax=axs[0])\n",
    "\n",
    "# Run the function to visualize model's coefficients\n",
    "visualize_coefficients(model.coef_, prices_perc_shifted.columns, ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dbf15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the output data up to \"2011-01\"\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 5))\n",
    "y.loc[:'2011-01'].plot(ax=axs[0])\n",
    "\n",
    "# Run the function to visualize model's coefficients\n",
    "visualize_coefficients(model.coef_, prices_perc_shifted.columns, ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fffcf5",
   "metadata": {},
   "source": [
    "# Train-test split with time series (TimeSeriesSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26ea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ShuffleSplit and create the cross-validation object\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, random_state=1)\n",
    "\n",
    "# Iterate through CV splits\n",
    "results = []\n",
    "for tr, tt in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    model.fit(X[tr], y[tr])\n",
    "\n",
    "    # Generate predictions on the test data, score the predictions, and collect\n",
    "    prediction = model.predict(X[tt])\n",
    "    score = r2_score(y[tt], prediction)\n",
    "    results.append((prediction, score, tt))\n",
    "    \n",
    "# Custom function to quickly visualize predictions\n",
    "visualize_predictions(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KFold cross-validation object\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=10, shuffle=False, random_state=1)\n",
    "\n",
    "# Iterate through CV splits\n",
    "results = []\n",
    "for tr, tt in cv.split(X, y):\n",
    "    # Fit the model on training data\n",
    "    model.fit(X[tr], y[tr])\n",
    "    \n",
    "    # Generate predictions on the test data and collect\n",
    "    prediction = model.predict(X[tt])\n",
    "    results.append((prediction, tt))\n",
    "    \n",
    "# Custom function to quickly visualize predictions\n",
    "visualize_predictions(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625fb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Create time-series cross-validation object\n",
    "cv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# Iterate through CV splits\n",
    "fig, ax = plt.subplots()\n",
    "for ii, (tr, tt) in enumerate(cv.split(X, y)):\n",
    "    # Plot the training data on each iteration, to see the behavior of the CV\n",
    "    ax.plot(tr, ii + y[tr])\n",
    "\n",
    "ax.set(title='Training data on each CV iteration', ylabel='CV iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dc8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def bootstrap_interval(data, percentiles=(2.5, 97.5), n_boots=100):\n",
    "    \"\"\"Bootstrap a confidence interval for the mean of columns of a 2-D dataset.\"\"\"\n",
    "    # Create empty array to fill the results\n",
    "    bootstrap_means = np.zeros([n_boots, data.shape[-1]])\n",
    "    for ii in range(n_boots):\n",
    "        # Generate random indices for data *with* replacement, then take the sample mean\n",
    "        random_sample = resample(data)\n",
    "        bootstrap_means[ii] = random_sample.mean(axis=0)\n",
    "\n",
    "    # Compute the percentiles of choice for the bootstrapped means\n",
    "    percentiles = np.percentile(bootstrap_means, percentiles, axis=0)\n",
    "    return percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa95fac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through CV splits\n",
    "n_splits = 100\n",
    "cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Create empty array to collect coefficients\n",
    "coefficients = np.zeros([n_splits, X.shape[1]])\n",
    "\n",
    "for ii, (tr, tt) in enumerate(cv.split(X, y)):\n",
    "    # Fit the model on training data and collect the coefficients\n",
    "    model.fit(X[tr], y[tr])\n",
    "    coefficients[ii] = model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a5777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Generate scores for each split to see how the model performs over time\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring=my_pearsonr)\n",
    "\n",
    "# Convert to a Pandas Series object\n",
    "scores_series = pd.Series(scores, index=times_scores, name='score')\n",
    "\n",
    "# Bootstrap a rolling confidence interval for the mean score\n",
    "scores_lo = scores_series.rolling(20).aggregate(partial(bootstrap_interval, percentiles=2.5))\n",
    "scores_hi = scores_series.rolling(20).aggregate(partial(bootstrap_interval, percentiles=97.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b87e67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce63c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f847642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bc7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e280a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307900a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2f44a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf4da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('Programacion_Cientifica')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "65e97ffa20fbdd895c76c3a1d2c2ade704754874d6e45df701862667e65d73d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
